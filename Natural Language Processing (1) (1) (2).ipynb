{"cells":[{"metadata":{},"id":"30819931","cell_type":"markdown","source":"# Basic Terminologies like Corpus , documents, vocabulary and word"},{"metadata":{},"id":"da280d09","cell_type":"markdown","source":"# Introduction to NLTK"},{"metadata":{},"id":"42ca606f","cell_type":"markdown","source":"# Difference between NLTK and Spacy Library "},{"metadata":{"trusted":true},"id":"4b0a0e10","cell_type":"code","source":"import nltk","execution_count":3,"outputs":[]},{"metadata":{"trusted":false},"id":"42f869af","cell_type":"code","source":"pip install nltk","execution_count":2,"outputs":[{"name":"stdout","output_type":"stream","text":"Collecting nltk\n  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\nRequirement already satisfied: click in /srv/conda/envs/notebook/lib/python3.10/site-packages (from nltk) (8.1.7)\nCollecting joblib (from nltk)\n  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\nCollecting regex>=2021.8.3 (from nltk)\n  Downloading regex-2024.7.24-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting tqdm (from nltk)\n  Downloading tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading regex-2024.7.24-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (776 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.5/776.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: tqdm, regex, joblib, nltk\nSuccessfully installed joblib-1.4.2 nltk-3.9.1 regex-2024.7.24 tqdm-4.66.5\nNote: you may need to restart the kernel to use updated packages.\n"}]},{"metadata":{"trusted":false},"id":"70112b09","cell_type":"code","source":"import nltk\nnltk.download('punkt')\nnltk.download('punkt_tab')","execution_count":10,"outputs":[{"name":"stderr","output_type":"stream","text":"[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package punkt_tab to /home/jovyan/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"},{"data":{"text/plain":"True"},"execution_count":10,"metadata":{},"output_type":"execute_result"}]},{"metadata":{"trusted":true},"id":"6b62a5a0","cell_type":"code","source":"## first i will define one corpus -> it is nothing but paragraph\ncorpus =\"\"\"\n    A paragraph is a series of sentences that are organized and coherent,\n    and are all related to a single topic. \n    Almost every piece of writing you do that is longer than a few sentences should be organized into paragraphs. \n    This is because paragraphs show a reader where the subdivisions of an essay begin and end, \n    and thus help the reader see the organization of the essay and grasp it's main points.\n\"\"\"","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"id":"1b1fda0d","cell_type":"code","source":"print(corpus)","execution_count":14,"outputs":[{"output_type":"stream","text":"\n    A paragraph is a series of sentences that are organized and coherent,\n    and are all related to a single topic. \n    Almost every piece of writing you do that is longer than a few sentences should be organized into paragraphs. \n    This is because paragraphs show a reader where the subdivisions of an essay begin and end, \n    and thus help the reader see the organization of the essay and grasp it's main points.\n\n","name":"stdout"}]},{"metadata":{},"id":"55bd0e21","cell_type":"markdown","source":"# Tokenization "},{"metadata":{"trusted":true},"id":"b3176786","cell_type":"code","source":"## 1) convert the paragraph into sentences\n## we can do this using NLTK library easily\n## this tokenize is library in nltk which has one method called sent_tokenize which will help us to convert paragraph into sentences\nfrom nltk.tokenize import sent_tokenize ","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"id":"7613af54","cell_type":"code","source":"## i will just use this method\n## it is converting paragraph into list of sentences i.e tokens\ndocuments=sent_tokenize(corpus)","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"id":"92414c58","cell_type":"code","source":"## we can also check type of documents\ntype(documents)","execution_count":17,"outputs":[{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"list"},"metadata":{}}]},{"metadata":{"trusted":true},"id":"aba8e414","cell_type":"code","source":"## now i wil iterate through this list\nfor sentence in documents:\n    print('-->', sentence)","execution_count":18,"outputs":[{"output_type":"stream","text":"--> \n    A paragraph is a series of sentences that are organized and coherent,\n    and are all related to a single topic.\n--> Almost every piece of writing you do that is longer than a few sentences should be organized into paragraphs.\n--> This is because paragraphs show a reader where the subdivisions of an essay begin and end, \n    and thus help the reader see the organization of the essay and grasp it's main points.\n","name":"stdout"}]},{"metadata":{"trusted":true},"id":"74d06cde","cell_type":"code","source":"## 2) now we will see how we can convert paragraph into words\n## and also sentence into words\nfrom nltk.tokenize import word_tokenize","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"id":"db2629f8","cell_type":"code","source":"paragraph_to_words = word_tokenize(corpus)","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"id":"60c6ad02","cell_type":"code","source":"paragraph_to_words","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"['A',\n 'paragraph',\n 'is',\n 'a',\n 'series',\n 'of',\n 'sentences',\n 'that',\n 'are',\n 'organized',\n 'and',\n 'coherent',\n ',',\n 'and',\n 'are',\n 'all',\n 'related',\n 'to',\n 'a',\n 'single',\n 'topic',\n '.',\n 'Almost',\n 'every',\n 'piece',\n 'of',\n 'writing',\n 'you',\n 'do',\n 'that',\n 'is',\n 'longer',\n 'than',\n 'a',\n 'few',\n 'sentences',\n 'should',\n 'be',\n 'organized',\n 'into',\n 'paragraphs',\n '.',\n 'This',\n 'is',\n 'because',\n 'paragraphs',\n 'show',\n 'a',\n 'reader',\n 'where',\n 'the',\n 'subdivisions',\n 'of',\n 'an',\n 'essay',\n 'begin',\n 'and',\n 'end',\n ',',\n 'and',\n 'thus',\n 'help',\n 'the',\n 'reader',\n 'see',\n 'the',\n 'organization',\n 'of',\n 'the',\n 'essay',\n 'and',\n 'grasp',\n 'it',\n \"'s\",\n 'main',\n 'points',\n '.']"},"metadata":{}}]},{"metadata":{"trusted":true},"id":"3a90c905","cell_type":"code","source":"for sentence in documents:\n    print(word_tokenize(sentence))","execution_count":22,"outputs":[{"output_type":"stream","text":"['A', 'paragraph', 'is', 'a', 'series', 'of', 'sentences', 'that', 'are', 'organized', 'and', 'coherent', ',', 'and', 'are', 'all', 'related', 'to', 'a', 'single', 'topic', '.']\n['Almost', 'every', 'piece', 'of', 'writing', 'you', 'do', 'that', 'is', 'longer', 'than', 'a', 'few', 'sentences', 'should', 'be', 'organized', 'into', 'paragraphs', '.']\n['This', 'is', 'because', 'paragraphs', 'show', 'a', 'reader', 'where', 'the', 'subdivisions', 'of', 'an', 'essay', 'begin', 'and', 'end', ',', 'and', 'thus', 'help', 'the', 'reader', 'see', 'the', 'organization', 'of', 'the', 'essay', 'and', 'grasp', 'it', \"'s\", 'main', 'points', '.']\n","name":"stdout"}]},{"metadata":{"trusted":true},"id":"0991241e","cell_type":"code","source":"from nltk.tokenize import wordpunct_tokenize","execution_count":30,"outputs":[]},{"metadata":{"trusted":true},"id":"565fb40b","cell_type":"code","source":"wordpunct_tokenize(corpus)","execution_count":31,"outputs":[{"output_type":"execute_result","execution_count":31,"data":{"text/plain":"['A',\n 'paragraph',\n 'is',\n 'a',\n 'series',\n 'of',\n 'sentences',\n 'that',\n 'are',\n 'organized',\n 'and',\n 'coherent',\n ',',\n 'and',\n 'are',\n 'all',\n 'related',\n 'to',\n 'a',\n 'single',\n 'topic',\n '.',\n 'Almost',\n 'every',\n 'piece',\n 'of',\n 'writing',\n 'you',\n 'do',\n 'that',\n 'is',\n 'longer',\n 'than',\n 'a',\n 'few',\n 'sentences',\n 'should',\n 'be',\n 'organized',\n 'into',\n 'paragraphs',\n '.',\n 'This',\n 'is',\n 'because',\n 'paragraphs',\n 'show',\n 'a',\n 'reader',\n 'where',\n 'the',\n 'subdivisions',\n 'of',\n 'an',\n 'essay',\n 'begin',\n 'and',\n 'end',\n ',',\n 'and',\n 'thus',\n 'help',\n 'the',\n 'reader',\n 'see',\n 'the',\n 'organization',\n 'of',\n 'the',\n 'essay',\n 'and',\n 'grasp',\n 'it',\n \"'\",\n 's',\n 'main',\n 'points',\n '.']"},"metadata":{}}]},{"metadata":{"trusted":true},"id":"40afeae1","cell_type":"code","source":"from nltk.tokenize import TreebankWordTokenizer ## ","execution_count":32,"outputs":[]},{"metadata":{},"id":"eae2e7c6","cell_type":"raw","source":"tokenizer=TreebankWordTokenizer()"},{"metadata":{"trusted":true},"id":"aad9af24","cell_type":"code","source":"tokenizer.tokenize(corpus)","execution_count":33,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'tokenizer' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241m.\u001b[39mtokenize(corpus)\n","\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"]}]},{"metadata":{},"id":"71b67035","cell_type":"markdown","source":"# Removing StopWords"},{"metadata":{"trusted":true},"id":"1d234470","cell_type":"code","source":"from nltk.corpus import stopwords\nnltk.download('stopwords')","execution_count":34,"outputs":[{"output_type":"stream","text":"[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","name":"stderr"},{"output_type":"execute_result","execution_count":34,"data":{"text/plain":"True"},"metadata":{}}]},{"metadata":{"trusted":true},"id":"c0381a0b","cell_type":"code","source":"stop_words = stopwords.words('english')","execution_count":35,"outputs":[]},{"metadata":{"trusted":true},"id":"e20122cf","cell_type":"code","source":"stop_words","execution_count":36,"outputs":[{"output_type":"execute_result","execution_count":36,"data":{"text/plain":"['i',\n 'me',\n 'my',\n 'myself',\n 'we',\n 'our',\n 'ours',\n 'ourselves',\n 'you',\n \"you're\",\n \"you've\",\n \"you'll\",\n \"you'd\",\n 'your',\n 'yours',\n 'yourself',\n 'yourselves',\n 'he',\n 'him',\n 'his',\n 'himself',\n 'she',\n \"she's\",\n 'her',\n 'hers',\n 'herself',\n 'it',\n \"it's\",\n 'its',\n 'itself',\n 'they',\n 'them',\n 'their',\n 'theirs',\n 'themselves',\n 'what',\n 'which',\n 'who',\n 'whom',\n 'this',\n 'that',\n \"that'll\",\n 'these',\n 'those',\n 'am',\n 'is',\n 'are',\n 'was',\n 'were',\n 'be',\n 'been',\n 'being',\n 'have',\n 'has',\n 'had',\n 'having',\n 'do',\n 'does',\n 'did',\n 'doing',\n 'a',\n 'an',\n 'the',\n 'and',\n 'but',\n 'if',\n 'or',\n 'because',\n 'as',\n 'until',\n 'while',\n 'of',\n 'at',\n 'by',\n 'for',\n 'with',\n 'about',\n 'against',\n 'between',\n 'into',\n 'through',\n 'during',\n 'before',\n 'after',\n 'above',\n 'below',\n 'to',\n 'from',\n 'up',\n 'down',\n 'in',\n 'out',\n 'on',\n 'off',\n 'over',\n 'under',\n 'again',\n 'further',\n 'then',\n 'once',\n 'here',\n 'there',\n 'when',\n 'where',\n 'why',\n 'how',\n 'all',\n 'any',\n 'both',\n 'each',\n 'few',\n 'more',\n 'most',\n 'other',\n 'some',\n 'such',\n 'no',\n 'nor',\n 'not',\n 'only',\n 'own',\n 'same',\n 'so',\n 'than',\n 'too',\n 'very',\n 's',\n 't',\n 'can',\n 'will',\n 'just',\n 'don',\n \"don't\",\n 'should',\n \"should've\",\n 'now',\n 'd',\n 'll',\n 'm',\n 'o',\n 're',\n 've',\n 'y',\n 'ain',\n 'aren',\n \"aren't\",\n 'couldn',\n \"couldn't\",\n 'didn',\n \"didn't\",\n 'doesn',\n \"doesn't\",\n 'hadn',\n \"hadn't\",\n 'hasn',\n \"hasn't\",\n 'haven',\n \"haven't\",\n 'isn',\n \"isn't\",\n 'ma',\n 'mightn',\n \"mightn't\",\n 'mustn',\n \"mustn't\",\n 'needn',\n \"needn't\",\n 'shan',\n \"shan't\",\n 'shouldn',\n \"shouldn't\",\n 'wasn',\n \"wasn't\",\n 'weren',\n \"weren't\",\n 'won',\n \"won't\",\n 'wouldn',\n \"wouldn't\"]"},"metadata":{}}]},{"metadata":{"trusted":true},"id":"adfb7051","cell_type":"code","source":"corpus","execution_count":37,"outputs":[{"output_type":"execute_result","execution_count":37,"data":{"text/plain":"\"\\n    A paragraph is a series of sentences that are organized and coherent,\\n    and are all related to a single topic. \\n    Almost every piece of writing you do that is longer than a few sentences should be organized into paragraphs. \\n    This is because paragraphs show a reader where the subdivisions of an essay begin and end, \\n    and thus help the reader see the organization of the essay and grasp it's main points.\\n\""},"metadata":{}}]},{"metadata":{"trusted":true},"id":"f487fc7d","cell_type":"code","source":"paragraph_to_words","execution_count":38,"outputs":[{"output_type":"execute_result","execution_count":38,"data":{"text/plain":"['A',\n 'paragraph',\n 'is',\n 'a',\n 'series',\n 'of',\n 'sentences',\n 'that',\n 'are',\n 'organized',\n 'and',\n 'coherent',\n ',',\n 'and',\n 'are',\n 'all',\n 'related',\n 'to',\n 'a',\n 'single',\n 'topic',\n '.',\n 'Almost',\n 'every',\n 'piece',\n 'of',\n 'writing',\n 'you',\n 'do',\n 'that',\n 'is',\n 'longer',\n 'than',\n 'a',\n 'few',\n 'sentences',\n 'should',\n 'be',\n 'organized',\n 'into',\n 'paragraphs',\n '.',\n 'This',\n 'is',\n 'because',\n 'paragraphs',\n 'show',\n 'a',\n 'reader',\n 'where',\n 'the',\n 'subdivisions',\n 'of',\n 'an',\n 'essay',\n 'begin',\n 'and',\n 'end',\n ',',\n 'and',\n 'thus',\n 'help',\n 'the',\n 'reader',\n 'see',\n 'the',\n 'organization',\n 'of',\n 'the',\n 'essay',\n 'and',\n 'grasp',\n 'it',\n \"'s\",\n 'main',\n 'points',\n '.']"},"metadata":{}}]},{"metadata":{"trusted":true},"id":"4ec28822","cell_type":"code","source":" ## let me first make a list \n\nnew_list=[]\n\n\nfor words in paragraph_to_words:\n    if words.lower() not in stop_words:\n        new_list.append(words)\n\nfilter_corpus=' '.join(new_list)\n\n\n## this entire for loop can also be written as List Comprehension in python\n\nnew_list = [words for words in paragraph_to_words if words.lower() not in stop_words]\nfilter_corpus=' '.join(new_list)","execution_count":49,"outputs":[]},{"metadata":{"trusted":true},"id":"896f9fce","cell_type":"code","source":"print(filter_corpus)","execution_count":50,"outputs":[{"output_type":"stream","text":"paragraph series sentences organized coherent , related single topic . Almost every piece writing longer sentences organized paragraphs . paragraphs show reader subdivisions essay begin end , thus help reader see organization essay grasp 's main points .\n","name":"stdout"}]},{"metadata":{"trusted":true},"id":"a2b943b7","cell_type":"code","source":"","execution_count":41,"outputs":[{"output_type":"execute_result","execution_count":41,"data":{"text/plain":"\"\\n    A paragraph is a series of sentences that are organized and coherent,\\n    and are all related to a single topic. \\n    Almost every piece of writing you do that is longer than a few sentences should be organized into paragraphs. \\n    This is because paragraphs show a reader where the subdivisions of an essay begin and end, \\n    and thus help the reader see the organization of the essay and grasp it's main points.\\n\""},"metadata":{}}]},{"metadata":{"trusted":true},"id":"8ff267d1","cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":5}